---
title: "STAT480-Simulation"
author: "Quan Zhao"
date: "2023-12-19"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
set.seed(123)
```


## PDF and CDF of dist

PDF of student's t-distribution

$$
f(t) = \frac{\Gamma\left(\frac{\nu + 1}{2}\right)}{\sqrt{\nu\pi}\,\Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{t^2}{\nu} \right)^{-\frac{\nu + 1}{2}}
$$

CDF of student's t-distribution

$$
F(t) = \int_{-\infty}^{t} f(u)\, du
$$

```{r}
# Student's t PDF
student_t_pdf <- function(t, nu) {
  gamma((nu + 1) / 2) / (sqrt(nu * pi) * gamma(nu / 2)) * (1 + (t^2) / nu)^(-(nu + 1) / 2)
}

# Student's t CDF (using numerical integration)
student_t_cdf <- function(t, nu) {
  integrate(function(x) student_t_pdf(x, nu), lower = -Inf, upper = t)$value
}

# Example usage
nu <- 5 # degrees of freedom
t_value <- 2

# Calculate PDF
pdf_value <- student_t_pdf(t_value, nu)

# Calculate CDF
cdf_value <- student_t_cdf(t_value, nu)

# Print results
print(paste("PDF at t =", t_value, ":", pdf_value))
print(paste("CDF at t =", t_value, ":", cdf_value))

```

# Plot examples of the density; display the parameters that you chose.

```{r}
# Load necessary library
library(ggplot2)

# Set degrees of freedom
nu <- 5

plot_dist <- function(nu) {

# Create a sequence of t values
t_values <- seq(-5, 5, by = 0.1)

# Calculate PDF and CDF for each t value
pdf_values <- sapply(t_values, student_t_pdf, nu = nu)
cdf_values <- sapply(t_values, student_t_cdf, nu = nu)

# Create a data frame for plotting
data_for_plot <- data.frame(t = t_values, PDF = pdf_values, CDF = cdf_values)

# Plot PDF
pdf_plot <- ggplot(data_for_plot, aes(x = t, y = PDF)) +
  geom_line(color = 'blue') +
  ggtitle('PDF of Student\'s t-Distribution') +
  xlab('t value') +
  ylab('Density')

# Plot CDF
cdf_plot <- ggplot(data_for_plot, aes(x = t, y = CDF)) +
  geom_line(color = 'red') +
  ggtitle('CDF of Student\'s t-Distribution') +
  xlab('t value') +
  ylab('Cumulative Probability')

# Display plots
print(pdf_plot)
print(cdf_plot)
}

plot_dist(nu)
```

When the Degree of freedom is 1, then Student's t-distribution is standard Cauchy distribution.

```{r}
nu <- 1
plot_dist(nu)
```

# Propose your own pseudorandom number generator that produces deviates from the Student's t distribution

```{r}
generate_t_distribution <- function(n, nu) {
  Z <- rnorm(n)
  X <- rchisq(n, df = nu)
  T <- Z / sqrt(X / nu)
  return(T)
}

# Example usage
n <- 1000    # number of random values to generate
nu <- 5      # degrees of freedom
t_values <- generate_t_distribution(n, nu)

# You can plot to see the distribution
hist(t_values, breaks = 30, main = "Generated Student's t-Distribution", xlab = "T-values")

```

# 5. Given $X = (X_{1},X_{2}, ...,X_{n})$ a random sample of i.i.d. Student's t variables,

## obtain your own ***maximum likelihood estimator*** for (a,b), say $\widehat{(a,b)}_{ML}$. Implement it.

```{r}
# Student's t PDF function
student_t_pdf <- function(t, nu) {
  gamma((nu + 1) / 2) / (sqrt(nu * pi) * gamma(nu / 2)) * (1 + (t^2) / nu)^(-(nu + 1) / 2)
}

# Log-Likelihood function using the custom Student's t PDF
log_likelihood_t <- function(v, data) {
  sum(log(sapply(data, student_t_pdf, nu = v)))
}

# Function to find MLE of degrees of freedom (v)
mle_t_distribution <- function(data) {
  # Ensure data does not contain non-finite values
  data <- data[is.finite(data)]
  
  # Optim function with bounds for v and adjusted initial value
  mle <- optim(par = 4, fn = function(v) -log_likelihood_t(v, data), 
               method = "L-BFGS-B", lower = 2, upper = 30, control = list(fnscale = -1))
  return(mle$par)
}

# Generate random data using the custom Student's t distribution function
data_sample <- generate_t_distribution(100, 5)  # Example data generation

# Estimate degrees of freedom using MLE
estimated_v <- mle_t_distribution(data_sample)
print(estimated_v)

```


# Improve by Bootstrap

```{r}
# Bootstrap-enhanced MLE function
bootstrap_mle_t_distribution <- function(original_data, n_bootstrap = 1000) {
  bootstrap_estimates <- numeric(n_bootstrap)

  for (i in 1:n_bootstrap) {
    # Create a bootstrap sample
    bootstrap_sample <- sample(original_data, size = length(original_data), replace = TRUE)

    # Estimate v using MLE for the bootstrap sample
    estimated_v <- optim(par = 4, fn = function(v) -log_likelihood_t(v, bootstrap_sample), 
                         method = "L-BFGS-B", lower = 2, upper = 30, control = list(fnscale = -1))$par
    bootstrap_estimates[i] <- estimated_v
  }

  # Aggregate results: mean or median can be used
  final_estimate <- mean(bootstrap_estimates)
  return(list(estimate = final_estimate, bootstrap_estimates = bootstrap_estimates))
}

# Example usage
data_sample <- generate_t_distribution(100, 5)  # Generate sample data
result <- bootstrap_mle_t_distribution(data_sample)
print(result$estimate)

```


# estimate sample
```{r}
library(reshape2)
```


```{r}
set.seed(seed=1234567890, kind="Mersenne-Twister")

N <- c(5, 10, 100)
Rf <- 30000 # There will be 6000, 3000, and 300 replications for each element in N
Output <- NULL

for(n in N){ # Loop for first factor
  for(r in 1:round(Rf/n)){ # Replications loop
    x <- rexp(n) # Same sample for all estimators
    Output <- rbind(Output, 
                    c(n,
                      mean(x),
                      median(x)/log(2)))
  }
}

Output <- data.frame(Output)
names(Output) <- c("n", "ML", "Med")
Output$n <- as.factor(Output$n)

Output.melt <- melt(data=Output, 
                    id.vars=1,
                    measure.vars=2:3,
                    variable.name="Estimator",
                    value.name="Estimates")
```

```{r}
ggplot(Output.melt, aes(x=Estimates, col=Estimator)) +
  geom_vline(xintercept = 1, col="gray") +
  geom_density(linewidth=1.2) +
  ylab("Empirical densities") +
  facet_wrap(~n)
```


